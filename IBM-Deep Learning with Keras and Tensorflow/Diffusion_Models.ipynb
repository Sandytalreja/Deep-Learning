{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    Acquire practical understanding of diffusion model architectures, data processing, model training, and performance evaluation\n",
        "    Implement, train, and evaluate diffusion models using Keras\n"
      ],
      "metadata": {
        "id": "iHp7yO51hEqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 : Preprocess Data**\n",
        "\n",
        "Prepare the MNIST data set for training by normalizing the pixel values and reshaping the images to have a single color channel. Normalization helps in faster convergence during training, and reshaping is required because the input layer of your diffusion model expects a three-dimensional tensor.\n",
        "\n",
        "1. Load and preprocess the MNIST data set:\n",
        "\n",
        "    Use Keras to load the MNIST data set.\n",
        "    Normalize the image pixel values to the range [0, 1].\n",
        "\n",
        "2. Reshape the Data:\n",
        "\n",
        "    Expand the dimensions of the images to match the input shape required by the model (28x28x1).\n"
      ],
      "metadata": {
        "id": "9lpY7V0FhHPZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D3cgpi70g9Pq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Suppress oneDNN optimizations and lower TensorFlow logging level\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the data set\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Expand dimensions to match the input shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# Add noise to the data\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "\n",
        "# Clip the values to be within the range [0, 1]\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n"
      ],
      "metadata": {
        "id": "-xJ8JYLPht9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 : Build the diffusion model**\n",
        "\n",
        "Build a simple diffusion model with an encoder that compresses the input image into a latent representation and a decoder that reconstructs the image from this representation. The model is compiled with the Adam optimizer and binary cross-entropy loss.\n",
        "\n",
        "1. Define the encoder:\n",
        "\n",
        "    Create an input layer with the shape (28, 28, 1).\n",
        "    Add two Conv2D layers with increasing filter sizes and ReLU activation.\n",
        "\n",
        "2. Define the bottleneck:\n",
        "\n",
        "    Add a flattened layer followed by a dense layer with ReLU activation.\n",
        "\n",
        "3. Define the decoder:\n",
        "\n",
        "    Add a Dense layer to expand the bottleneck representation.\n",
        "    Reshape the output to match the original image dimensions.\n",
        "    Add two Conv2DTranspose layers with decreasing filter sizes and ReLU activation.\n",
        "\n",
        "4. Compile the model:\n",
        "\n",
        "    Use the Adam optimizer and binary cross-entropy loss.\n"
      ],
      "metadata": {
        "id": "RlQB-JLHjozI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the diffusion model architecture with reduced complexity\n",
        "input_layer = Input(shape=(28, 28, 1))\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)  # Reduced filters\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)  # Reduced size\n",
        "x = Dense(28*28*32, activation='relu')(x)  # Reduced size\n",
        "x = Reshape((28, 28, 32))(x)\n",
        "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
        "x = Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
        "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "diffusion_model = Model(input_layer, output_layer)\n",
        "\n",
        "# Compile the model with mixed precision and a different loss function\n",
        "diffusion_model.compile(optimizer='adam', loss='mean_squared_error')  # Using MSE for regression tasks\n",
        "\n",
        "# Summary of the optimized model\n",
        "diffusion_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "kZbRBrmSjnLo",
        "outputId": "4b5dce97-c836-42d3-8f8b-55a9e1310a69"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Input' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-07245398efc1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the diffusion model architecture with reduced complexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reduced filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reduced filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 : Add Noise to the data**\n",
        "\n",
        "Add random noise to the data set to simulate the diffusion process:\n",
        "\n",
        "    Add Gaussian noise to the training and test data sets.\n",
        "    Clip the values to ensure they remain within the valid range [0, 1]."
      ],
      "metadata": {
        "id": "Bqmrs2hymZYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cache and prefetch the data using TensorFlow data pipelines for faster loading\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_noisy, x_train))\n",
        "train_dataset = train_dataset.cache().batch(64).prefetch(tf.data.AUTOTUNE)  # Reduced batch size\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_test_noisy, x_test))\n",
        "val_dataset = val_dataset.cache().batch(64).prefetch(tf.data.AUTOTUNE)  # Reduced batch size\n"
      ],
      "metadata": {
        "id": "RIv3K-JQmGI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the diffusion model**\n",
        "\n",
        "rain the diffusion model to denoise the MINIST images. Use the noisy images as input and the original images as the target, learning to reverse the noise addition process.\n",
        "\n",
        "    Use the ‘fit’ method to train the model on the noisy training data.\n",
        "    Set the number of epochs to 50 and the batch size to 128.\n"
      ],
      "metadata": {
        "id": "oq2_EXetn_D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement early stopping based on validation loss\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping and smaller batch size\n",
        "diffusion_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=3,\n",
        "    shuffle=True,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "WKWhXiKrn7jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Evaluate the diffusion model**\n",
        "\n",
        "Evaluate the performance of the trained diffusion model by predicting the denoised images and visualizing the results. Comparing the original, noisy, and denoised images will help you understand how well the model has learned to remove noise from the images.\n",
        "\n",
        "1. Reconstruct images:\n",
        "\n",
        "    Use the diffusion model to predict the denoised test images.\n",
        "    Compare the original, noisy, and denoised images.\n",
        "\n",
        "2. Visualize the results:\n",
        "\n",
        "    Plot a few examples of original, noisy, and denoised images side by side.\n"
      ],
      "metadata": {
        "id": "j1ZiG7_hparo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict the denoised images\n",
        "denoised_images = diffusion_model.predict(x_test_noisy)\n",
        "\n",
        "# Visualize the results\n",
        "n = 10  # Number of digits to display\n",
        "plt.figure(figsize=(20, 6))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display noisy\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display denoised\n",
        "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
        "    plt.imshow(denoised_images[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HO4X5dD1oqa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Fine-tune the diffusion model**\n",
        "\n",
        "Fine-tune the diffusion model by unfreezing some layers and retraining the model to improve its performance.\n",
        "\n",
        "1. Unfreeze the model layers:\n",
        "\n",
        "    Unfreeze the last few layers of the model to allow them to be retrained.\n",
        "\n",
        "2. Compile and train the model:\n",
        "\n",
        "    Recompile the model.\n",
        "    Train the model again for an additional 10 epochs.\n"
      ],
      "metadata": {
        "id": "Q_iY4VFoqLRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the top layers of the model\n",
        "for layer in diffusion_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Compile the model again\n",
        "diffusion_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the model again\n",
        "diffusion_model.fit(x_train_noisy, x_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=64,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(x_test_noisy, x_test))\n"
      ],
      "metadata": {
        "id": "gmh07Z2ZqOpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize the effect of noise**\n",
        "Objective:\n",
        "\n",
        "    Compare the impact of different noise levels on the denoising performance of the model.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "    Add noise with different factors (e.g., 0.1, 0.5, 0.7) to the test data.\n",
        "    Use the model to predict the denoised images for each noise level.\n",
        "    Visualize the original, noisy, and denoised images side by side for each noise level.\n"
      ],
      "metadata": {
        "id": "pNFGR_IFqsit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Function to add noise and predict denoised images\n",
        "def add_noise_and_predict(noise_factor):\n",
        "    x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "    x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "    denoised_images = diffusion_model.predict(x_test_noisy)\n",
        "    return x_test_noisy, denoised_images\n",
        "\n",
        "# Noise levels to test\n",
        "noise_levels = [0.1, 0.5, 0.7]\n",
        "\n",
        "# Visualize the results\n",
        "n = 5  # Number of digits to display\n",
        "plt.figure(figsize=(20, 12))\n",
        "for idx, noise_factor in enumerate(noise_levels):\n",
        "    x_test_noisy, denoised_images = add_noise_and_predict(noise_factor)\n",
        "\n",
        "    for i in range(n):\n",
        "        # Display original\n",
        "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + idx * 3 * n)\n",
        "        plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        if i == 0:\n",
        "            ax.set_title(f'Original (Noise: {noise_factor})')\n",
        "\n",
        "        # Display noisy\n",
        "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + n + idx * 3 * n)\n",
        "        plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "\n",
        "        # Display denoised\n",
        "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + 2 * n + idx * 3 * n)\n",
        "        plt.imshow(denoised_images[i].reshape(28, 28), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n",
        "Summary"
      ],
      "metadata": {
        "id": "yRswpeq7qrkn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}